<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Quiz Yourself]]></title>
      <url>%2F2017%2F04%2FQuiz-Yourself%2Findex.html</url>
      <content type="text"><![CDATA[Java Magazine MarchApril 2017]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java 对象指针压缩]]></title>
      <url>%2F2017%2F04%2FJava-%E5%AF%B9%E8%B1%A1%E6%8C%87%E9%92%88%E5%8E%8B%E7%BC%A9%2Findex.html</url>
      <content type="text"><![CDATA[很久之前就看到过 Java 对象指针压缩这个技术，只是一直没具体想为什么要偏移 3 位，好吧，最近才知道原因是因为大多数 JVM 实现都是采用 8 位对齐，所以二进制位中的后三位都是 0。 Let’s talk a bit about Ordinary Object Pointers (OOPs) and Compressed OOPs (Coops). OOPs are the handles/pointers the JVM uses as object references. When oops are only 32 bits long, they can reference only 4 GB of memory, which is why a 32-bit JVM is limited to a 4 GB heap size. (The same restriction applies at the operating system level, which is why any 32-bit process is limited to 4GB of address space.) When oops are 64 bits long, they can reference terabytes of memory.What if there were 35-bit oops? Then the pointer could reference 32 GB of memory and still take up less space in the heap than 64-bit references. The problem is that there aren’t 35-bit registers in which to store such references. Instead, though, the JVM can assume that the last 3 bits of the reference are all 0. Now every reference can be stored in 32 bits in the heap. When the reference is stored into a 64-bit register, the JVM can shift it left by 3 bits (adding three zeros at the end). When the reference is saved from a register, the JVM can right-shift it by 3 bits, discarding the zeros at the end.This allows JVM to use pointers that can reference 32 GB of memory while using only 32 bits in the heap. However it also means that the JVM cannot access any object at an address that isn’t divisible by 8, since any address from a compressed oop ends with three zeros. The first possible oop is 0x1, which when shifted becomes 0x8. The next oop is 0x2, which when shifted becomes 0x10 (16). Objects must therefore be located on an 8-byte boundary. As we know objects are already aligned on an 8-byte boundary in the JVM (in both the 32- and 64-bit versions); this is the optimal alignment for most processors. So nothing is lost by using compressed oops.A program that uses a 31 GB heap and compressed oops will usually be faster than a program that uses a 33 GB heap. Although the 33 GB heap is larger, the extra space used by the pointers in that heap means that the larger heap will perform more frequent GC cycles and have worse performance.Compressed oops are enabled using the -XX:+UseCompressedOops flag; in Java 7 and later versions, they are enabled by default whenever the maximum heap size is less than 32 GB. Java Object header]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java 对象内存布局]]></title>
      <url>%2F2017%2F04%2FJava-%E5%AF%B9%E8%B1%A1%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80%2Findex.html</url>
      <content type="text"><![CDATA[我把示例代码放了一份在 Github 上，jol-samples，想看的同学可以 clone 下来把每个 example 跑一跑就能看到 JVM 对象在内存中布局的一些信息，包括对象头占多大、字节怎么对齐、字段在内存中的顺序不一定与声明的顺序一致、涉及到继承时字段是如何存放的、带 transient 修饰符的字段被特殊处理、Java8 新增的 @Contended 注解的作用、JVM 的平台相关性、对象头中的 mark word 及 class word、轻量锁、偏向锁、重量锁、Hashcode、GC 需要用到的对象引用图、哈希碰撞时转换为链表以及 Java8 中极端情况下转换为红黑树、观察 mark word 中的 age 字段的值在 GC 后的变化 等等，我没有一个一个写出来，因为 25 个例子太多了，设计到的知识点也比较多，需要一些前置知识才能理解。JOL (Java Object Layout) is the tiny toolbox to analyze object layout schemes in JVMs. These tools are using Unsafe, JVMTI, and Serviceability Agent (SA) heavily to decoder the actual object layout, footprint, and references. This makes JOL much more accurate than other tools relying on heap dumps, specification assumptions, etc. 以下是在看到输出后可能会迷惑的地方： 首先要明确输出是大端字节序还是小端字节序，将二进制转换为十进制与后面的数字比较下就能确定。 伪共享、缓存一致性以及 Java8 中的 @Contended 注解，可能需要参考 False Sharing, Cache Coherence, and the @Contended Annotation on the Java 8 VM 及 深入理解Java虚拟机（第2版）。 Java8 中 HashMap 的变化，可参考 Java 8 HashMaps, Keys and the Comparable interface。 涉及到对象头的部分可能需要参考这篇文章，Java Object header，需要找到和你运行时 JVM 对应的平台相关的对象头来看，比如我在本地运行时是 64 位的 HotSpot JVM，就需要看最下面的基于 64 位的对象头。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Awesome article]]></title>
      <url>%2F2017%2F04%2FAwesome-article%2Findex.html</url>
      <content type="text"><![CDATA[CS 理解字节序 User space 与 Kernel space OLTP vs. OLAP Algorithm 小而巧的数字压缩算法：zigzag 多动态图详细讲解二叉搜索树 HTTP Comet：基于 HTTP 长连接的服务器推技术 HTTP/2.0 相比1.0有哪些重大改进？ HTTP persistent connection Maximum segment lifetime HTTP/2 for Front-End Developers TCP/IP The TCP/IP Guide TCP 三次握手和 Syn-Flood 攻击 一则经典技术面试题目的解读 What-happens-when What-happens-when (中文版) Java 一个简单代码的不简单实现 The substring() Method in JDK 6 and JDK 7 Java 8 HashMaps, Keys and the Comparable interface Java Thread Join Example Why is there a Java radix limit? Spring: your next Java microframework 探索 ConcurrentHashMap 高并发性的实现机制 Apache Tomcat Tuning for Production 并发框架Disruptor译文 Micro Benchmarking with JMH: Measure, don’t guess! JVM Java Object Header JVM Biased Locking Java性能优化指南1.8版，及唯品会的实战 Java Tuning Guide v1.8.pdf Linux What Is /dev/shm And Its Practical Usage tmpfs Linux TCP/IP Tuning for Scalability Others 当服务 QPS 增高时我们做什么 分布式锁 RESTful 架构风格下的 4 大常见安全问题 为什么文件名要小写？ 我回阿里的29个月 短 URL 系统是怎么设计的？]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[《网络是怎样连接的》笔记]]></title>
      <url>%2F2017%2F04%2F%E3%80%8A%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84%E3%80%8B%E7%AC%94%E8%AE%B0%2Findex.html</url>
      <content type="text"><![CDATA[浏览器生成消息 URL: Uniform Resource Locator，统一资源定位符。 URL: http://www.lab.glasscom.com/dir/，我们可以这样理解，以 “/” 结尾代表 /dir/ 后面本来应该有的文件名被省略了。根据 URL 的规则，文件名可以像前面这样省略。我们会在服务器上事先设置好文件名省略时要访问的默认文件名。这个设置根据服务器不同而不同，大多数情况下是 index.html 或者 default.htm 之类的文件名。 URI: Uniform Resource Identifier，统一资源标识符。 关于 HTTP 的 HEAD 方法，在我们仅仅需要 HTTP 响应头信息的时候就可以使用，比如不下载音视频的前提下通过 HEAD 方法查看一下字节数。这里推荐一个小工具 POSTMAN。 一般当我们访问 Web 服务器获取网页数据时，使用的就是 GET 方法。PUT、DELETE 等方法现在常用于 RESTful API 的设计中，在手机 App 和后端服务器交互时就会经常用到。 关于 GET 请求 URL 的最大长度，不同浏览器和服务器有不同的限制，可参考 Maximum URL Size in HTTP GET Request。 关于 ETag 这个字段，可以用来提供上次响应与下次请求之间的关联信息。上次响应中，服务器会通过 ETag 向客户端发送一个唯一标识，在下次请求中客户端可以通过 If-Match、If-None-Match、If-Range 字段将这个标识告知服务器，这样服务器就知道该请求和上次的响应是相关的。这个字段的功能和 Cookie 是相同的，但 Cookie 是网景（Netscape）公司自行开发的规格，而 Etag 是将其进行标准化后的规格。 HTTP 状态码摘要信息如下： 1xx 告知请求的处理进度和情况 2xx 成功 3xx 表示需要进一步操作 4xx 客户端错误 5xx 服务器错误 关于 DNS，可以参考 那些你未曾注意的DNS细节。 用电信号传输 TCP/IP 数据 最早的 TCP/IP 协议原型设计相当于现在的 TCP 和 IP 在一起的样子，后来才拆分为 TCP 和 IP 两个协议。 TCP 两端并没有像绳子一样的真实连接，只是两端都在维护着连接状态而已。 我们平时在 console 使用 netstat 命令看到的 0.0.0.0 表示本机上的所有 IP 地址。 IP 地址实际上并不是分配给计算机的，而是分配给网卡的，因此当计算机上存在多块网卡时，每一块网卡都会有自己的 IP 地址。在这里可以想到阿里云的 ECS 能看到公网的网络接口，而腾讯云的 CVM 只能看到内网的网络接口。是因为 CVM 实例不与公网直接通信，而通过 NAT 网关访问外网，应答请求。 MAC: Media Access Control 的缩写。以太网的每个帧前面都有报头和起始帧分界符（SFD），报头占前 7 字节，起始帧分界符占 1 字节，报头用于 “唤醒” 接收适配器，并且将它们的时钟和发送方的时钟同步。起始帧分界符的最后两个比特为 11，即警告适配器，“重要的内容” 就要来了。 发送和接收同时并行的方式叫作 “全双工”，相对地，某一时刻只能进行发送或接收其中一种操作的叫作 “半双工”。 根据以太网的规格，两台设备之间的网线不能超过 100 米，在这个距离内极少会发生错误。这是双绞线的情况，如果采用光纤可以更长，而且错误率不会上升。在使用集线器的半双工模式中，当发送信号时，接收线路不应该有信号进来，但情况不总是尽如人意，有很小的可能性出现多台设备同时进行发送操作的情况，一旦发生这种情况，两组信号就会发生叠加，无法彼此区分出来，这就是所谓的信号碰撞。这种情况下，继续发送信号是没有意义的，因此发送操作会终止。为了通知其他设备当前线路已发生碰撞，还会发送一段时间的阻塞信号，然后所有的发送操作会全部停止。等待一段时间后，网络中的设备会尝试重新发送信号。等待时间是根据 MAC 地址生成一个随机数计算出来的。当网络拥塞时，发生碰撞的可能性就会提高，重试发送的时候可能又会和另外一台设备的发送操作冲突，这时会将等待时间延长一倍，然后再次重试。以此类推，最多重试 10 次，如果还是不行就报告通信错误。上述都是半双工的情况，在全双工模式中不需要像半双工模式这样考虑这么多复杂的问题，即便接收线路中有信号进来，也可以直接发送信号。 在接收帧时，如果 FCS 校验没有问题，接下来就要看一下 MAC 头部中接收方 MAC 地址与网卡在初始化时分配给自己的 MAC 地址是否一致，以判断这个帧是不是发给自己的，如果不是自己的帧就直接丢弃。但这里也有特例，我们可以让网卡不检查帧的接收方地址，不管是不是自己的帧都统统接收下来，这种模式叫做 “混杂模式”（Promiscuous Mode）。好吧，笔者第一次在代码里看见 Promiscuous 时，随手到谷歌翻译一查，翻译过来是 “淫乱”，当时就凌乱了，finalspeed 中就用到了混杂模式。不过笔者认为 finalspeed 的代码写得比较乱，看了一些就没再看了。 从网线到网络设备 交换机并不只是简单地让信号流过，而是先接收信号并将其还原为数字信息，然后再重新转换成信号并发送出去的过程。交换机是基于以太网规格工作的设备，而路由器是基于 IP 工作的。交换机时通过 MAC 头部中的接收方 MAC 地址来判断转发目标的，而路由器则是根据 IP 头部中的 IP 地址来判断的。交换机在地址表中只匹配完全一致的记录，而路由器则会忽略主机号部分，只匹配网络号部分。 交换机端口的 MAC 模块不具有 MAC 地址。 当交换机发现一个包要发回到原端口时，就会直接丢弃这个包。当在地址表中找不到指定的 MAC 地址时，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。 在以太网中，当没有数据在传输时，网络中会填充一种被称为连接脉冲的脉冲信号。在没有数据信号时就填充连接脉冲，这使得网络中一直都有一定的信号流过，从而能够检测对方是否在正常工作，或者说网线有没有正常连接。以太网设备的网线接口周围有一个绿色的 LED 指示灯，它表示是否检测到正常的脉冲信号。如果绿灯亮，说明 PHY(MAU) 模块以及网线连接正常。 路由器的各个端口都具有 MAC 地址和 IP 地址。 路由器在进行匹配时首先寻找网络号比特数最长的一条记录，如果路由表中存在网络号长度相同的多条记录，这时，需要根据跃点计数的值来进行判断。跃点计数越小说明该路由越近，因此应选择跃点计数较小的记录。 路由器中子网掩码为 0.0.0.0 的记录表示 “默认路由”。 在路由器更新 TTL 和分片的过程中，IP 头部的内容发生了改变，因此必须重新计算校验和。 在内网中可用作私有地址的范围仅限以下这些： 10.0.0.0 ~ 10.255.255.255 172.16.0.0 ~ 172.31.255.255 192.168.0.0 ~ 192.168.255.255 NAT，上面讲腾讯云的 CVM 时提了下，细节可参考词条链接。关于 tcptwrecyle 的使用，可参考 优化Linux NAT网关。 通过接入网进入互联网内部 电信号和光信号传播的速度大体上相同，之所以电缆不如光纤通信速率高，是因为电信号在提升通信速率的同时，其衰减率也会提高，而光信号本来的衰减率就很低，提高通信速率也并不会提高衰减率。此外，光纤还不受电磁噪声的影响，因此光纤能够进行高速通信。 双绞线的极限距离时 100 米，但光纤的连接距离可以长达几公里。 ADSL: Asymmetric Digital Subscriber Line, 不对称数字用户线。它是一种利用架设在电线杆上的金属电话线来进行高速通信的技术，它的上行方向（用户到互联网）和下行方向（互联网到用户）的通信速率时不对称的。记得笔者家里起初安装网络时就是使用的 ADSL，并且速率只有 1Mbps，当时还不懂为什么下载速度最高只能达到 128 KB/s，后来才知道原因是 1 Byte 等于 8 bit 啊。 关于分离器：在信号从用户端发送出去时，电话和 ADSL 信号只是同时流到一条线路上而已，分离器实际上并没有做什么事。分离器的作用其实在相反的方向，也就是信号从电话线传入的时候。这时，分离器需要将电话和 ADSL 的信号进行分离。分离器将一定频率以上的信号过滤掉，也就是过滤掉了 ADSL 使用的高频信号，这样以来，只有电话信号才会传入电话机，但对于另一头的 ADSL Modem，则是传输原本的混合信号给它。ADSL Modem 内部已经具备将 ADSL 频率外的信号过滤掉的功能，因此不需要在分离器进行过滤。 光纤由一种双层结构的纤维状透明材质（玻璃和塑料）构成，ADSL 信号是由多个频段的信号组成的，比较复杂，但光信号却非常简单，亮表示 1，暗表示 0。数字信息并不能一下子变成光信号，而是先将数字信息转换成电信号，然后再将电信号转换成光信号。 Web 服务器程序解释请求消息并作出响应 在 HTTP1.0 中，是服务器先发起断开操作。 参考书目：《计算机网络 自顶向下方法》《TCP/IP详解 卷1 协议》]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[从一道面试题开始说起]]></title>
      <url>%2F2017%2F03%2F%E4%BB%8E%E4%B8%80%E9%81%93%E9%9D%A2%E8%AF%95%E9%A2%98%E5%BC%80%E5%A7%8B%E8%AF%B4%E8%B5%B7%2Findex.html</url>
      <content type="text"><![CDATA[其实这道题笔者在第二家的实习面试中被问到过，但是笔者当时并没有回答正确，所幸其他问题回答得还算不赖，没有因为这一个问题表现不佳而被挂掉。最近看《Wireshark 网络分析就这么简单》第一篇文章就是这道题。 让我们开始吧。 问题：两台服务器 A 和 B 的网络配置如下，B 的子网掩码本应该是 255.255.255.0，被不小心配成了 255.255.255.224。它们还能正常通信吗？ 服务器A： 服务器B： 这一篇文章在林沛满的博客中有记录，参见 Wireshark入门：第一次亲密接触。 如果你坚持看完了上面这篇林沛满先生的文章，那么回到这里。笔者在看完之后不太明白的是为什么在 B 看来 A 属于不同子网，而在 A 看来 B 属于同一子网，于是拿起纸和笔手动计算了一下。过程如下： 在服务器 B 看来，在往服务器 A 发送包之前，是仅仅知道服务器 A 的 IP 地址的，并不知道服务器 A 的子网掩码，所以服务器 B 使用自己的子网掩码与服务器 B 自身的 IP 地址相与得到服务器 B 的网络地址，然后继续使用服务器 B 的子网掩码与服务器 A 的 IP 地址相与得到服务器 A 的网络地址，根据 B 和 A 的网络地址是否相等来判断是否属于同一子网：B 的子网掩码为 255.255.255.224，二进制格式如下：111111111 11111111 11111111 11100000（B 的子网掩码） B 的 IP 地址为 192.168.26.3，二进制格式如下：111000000 10101000 00011010 00000011（B 的 IP 地址） 服务器 B 使用自己的子网掩码与服务器 B 自身的 IP 地址相与得到服务器 B 的网络地址为：111000000 10101000 00011010 00000000（B 的网络地址） A 的 IP 地址为 192.168.26.129，二进制格式如下：111000000 10101000 00011010 10000001（A 的 IP 地址） 使用服务器 B 的子网掩码与服务器 A 的 IP 地址相与得到服务器 A 的网络地址为：111000000 10101000 00011010 10000000（A 的网络地址） 通过以上结果，我们可以发现，在服务器 B 看来，B 的网络地址和 A 的网络地址是不同的，这也是服务器 B 通过 ARP 广播查询默认网关 MAC 地址的原因。 在服务器 A 看来：A 的子网掩码为 255.255.255.0，二进制格式如下：111111111 11111111 11111111 00000000（A 的子网掩码） A 的 IP 地址为 192.168.26.129，二进制格式如下：111000000 10101000 00011010 10000001（A 的 IP 地址） 服务器 A 使用自己的子网掩码与服务器 A 自身的 IP 地址相与得到服务器 A 的网络地址为：111000000 10101000 00011010 00000000（A 的网络地址） B 的 IP 地址为 192.168.26.3，二进制格式如下：111000000 10101000 00011010 00000011（B 的 IP 地址） 使用服务器 A 的子网掩码与服务器 B 的 IP 地址相与得到服务器 B 的网络地址为：111000000 10101000 00011010 00000000（B 的网络地址） 通过以上结果，我们可以发现，在服务器 A 看来，A 的网络地址和 B 的网络地址是相同的，这也是服务器 A 直接和服务器 B 进行通信的原因。 最后推荐下林沛满的这两本书：《Wireshark 网络分析就这么简单》，《Wireshark 网络分析的艺术》。可以说是是国内技术书籍中的上乘之作。这两本书让笔者对 TCP/UDP 有了更深入的理解，纸上得来终觉浅，绝知此事要躬行，只有自己亲自抓几个包看看才能真正理解相关细节。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[阿里巴巴Java开发手册 笔记]]></title>
      <url>%2F2017%2F02%2F%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4Java%E5%BC%80%E5%8F%91%E6%89%8B%E5%86%8C-%E7%AC%94%E8%AE%B0%2Findex.html</url>
      <content type="text"><![CDATA[编程规约 POJO 类中布尔类型的变量，都不要加 is ，否则部分框架解析会引起序列化错误。假设定义一个 boolean 的 isSuccess 属性，它的方法 Getter 被 IDE 生成为 isSuccess() ， RPC 等三方框架在反向解析的时候， “以为” 对应的属性名称是 success ，导致属性获取不到，进而抛出异常。这点也是笔者之前遇到过的，查了很久哪里的错最后发现是这个问题，不过经历一次后基本后面就能避免。 接口类中的方法和属性不要加任何修饰符号。包括在一些开源的代码里，笔者也经常看见在接口方法上声明 public 关键字的，这是冗余的，在 Java 规范中提到过。关于代码的规范及简洁性诸位可以参考 《重构 改善既有代码的设计》 及 《代码整洁之道》 。 方法体内的执行语句组、变量的定义语句组、不同的业务逻辑之间或者不同的语义之间插入一个空行。相同业务逻辑和语义之间不需要插入空行。不过没有必要插入多行空格进行隔开。这样可读性会明显提高，笔者经常看到部分开发人员的代码在很长的代码块里完全没有一个空行，没有按逻辑进行换行，这种习惯是不太好的。 所有的覆写方法，必须加 @Override 注解。这样 IDE 会检查合法性，有错误的话会及时提示。 所有的相同类型的包装类对象之间值的比较，全部使用 equals 方法比较。比如 Integer 的 -128 至 127 之间被缓存的对象可以直接使用 == 判断，因为被缓存了，是同一对象，地址相等，而这个区间外的却不能使用 == 判断，这也是面试时的一个常考点。 关于基本数据类型与包装数据类型：所有的 POJO 类属性必须使用包装数据类型，以便映射数据库中的 NULL ，局部变量推荐使用基本数据类型。 关于 hashCode 和 equals 的处理，遵循如下规则：只要重写 equals ，就必须重写 hashCode ，具体原因可参考《Effective java 中文版（第2版）》。 关于 ArrayList 里 subList 结果的注意事项，subList 只是 ArrayList 的一个视图，这部分大家可以参考 JDK 里的源码。 不要在 foreach 循环里进行元素的 remove/add 操作。remove 元素请使用 Iterator 方式，如果并发操作，需要对 Iterator 对象加锁。 在 JDK7 版本以上，Comparator 要满足自反性，传递性，对称性，不然 Arrays.sort， Collections.sort 会报 IllegalArgumentException 异常。这个在《Effective java 中文版（第2版）》中也有说明，虽然笔者之前看过，但在刚实习时的一个用于省份排序的代码里使用 Comparator 时还是忘了处理值相等的情况，所以，还是要实战后才能加深记忆。 集合初始化时，尽量指定集合初始值大小。这在笔者实习面试时也被问到，这块的话主要考察 ArrayList 的原理，内部机制，诸位看看JDK里 ArrayList 的原理就明白了。 创建线程或线程池时请指定有意义的线程名称，方便出错时回溯。 高并发时，同步调用应该去考量锁的性能损耗。能用无锁数据结构，就不要用锁；能锁区块，就不要锁整个方法体；能用对象锁，就不要用类锁。概括为一句话就是：尽量降低锁的粒度。 对多个资源、数据库表、对象同时加锁时，需要保持一致的加锁顺序，否则可能会造成死锁。关于并发这块可以参考 《Java并发编程实战》 ，个人认为这本在笔者看过Java并发的书籍里能算上乘之作，另外也可参考 《Java并发编程的艺术》 。 通过双重检查锁 (double-checked locking) (在并发场景) 实现延迟初始化的优化问题隐患 (可参考 The “Double-Checked Locking is Broken” Declaration) ，推荐问题解决方案中较为简单一种 (适用于 JDK5 及以上版本) ，将目标属性声明为 volatile 型。这部分涉及到两个重点，一是双重检查锁，二是 volatile 的原理及 Java 的主内存及每个线程的内存之间的关系。 volatile 只能解决多线程时的内存可见性问题，无法解决线程安全问题。可参考 Double checked locking 及 Initialization on demand holder idiom 。 注释掉的代码尽量要配合说明，而不是简单的注释掉。如果永久不用，建议直接删除，因为 Git 等版本控制系统保存了历史代码。 好的命名、代码结构是自解释的，注释力求精简准确、表达到位。避免无用的注释。 善用 TODO 及 FIXME ， IDE 可以方便的进行扫描。 获取当前毫秒数使用 System.currentTimeMillis()， System.nanoTime() 产生的值仅用于比较，同一时刻不同虚拟机 System.nanoTime() 返回的值可能不一样并且相差很大，笔者的同事已经踩过一次坑，关于 nanoTime 诸位可以看一看 JavaDoc 。 异常日志 不要捕获 Java 类库中定义的继承自 RuntimeException 的运行时异常类，如： IndexOutOfBoundsException / NullPointerException ，这类异常由程序员预检查来规避，保证程序健壮性。说到这里，异常继承结构图也可以看下。 捕获异常是为了处理它，不要捕获了却什么都不处理而抛弃之，如果不想处理它，请将该异常抛给它的调用者。最外层的业务使用者，必须处理异常，将其转化为用户可以理解的内容。 避免出现重复的代码 (Don’t Repeat Yourself) ，即 DRY 原则。关于这部分可参考 《程序员修炼之道》 。 谨慎地记录日志。生产环境禁止输出 debug 日志；有选择地输出 info 日志；如果使用 warn 来记录刚上线时的业务行为信息，一定要注意日志输出量的问题，避免把服务器磁盘撑爆，并记得及时删除这些观察日志。关于日志把 server 磁盘撑爆的问题，我司也出现过，后面加了相关监控来避免。 MySQL 规约 表达是与否概念的字段，必须使用 is_xxx 的方式命名，数据类型是 unsigned tinyint (1表示是，0表示否)，此规则同样适用于 odps 建表。任何字段如果为非负数，必须是 unsigned 。因为这样的话可用容量提升了一倍。 表名不使用复数名词。表名应该仅仅表示表里面的实体内容，不应该表示实体数量，对应于 DO 类名也是单数形式，符合表达习惯。 禁用保留字，如 desc、range、match、delayed 等，禁止在代码里对 SQL 关键字进行单独处理。 唯一索引名为 uk_ 字段名，普通索引名则为 idx_ 字段名。这样能让开发人员一眼就知道相关索引。 如果存储的字符串长度几乎相等，使用 char 定长字符串类型。 表必备三字段： id, gmt_create, gmt_modified 。其中 id 必为主键，类型为 unsigned bigint、单表时自增、步长为 1 。gmt_create, gmt_modified 的类型均为 date_time 类型。创建时间与修改时间需要记录笔者理解，不理解的为什么要用 gmt 开头，北京时间应该是 GMT + 8:00 啊。 字段允许适当冗余，以提高性能，但是必须考虑数据同步的情况。冗余字段应遵循：不是频繁修改的字段；不是 varchar 超长字段，更不能是 text 字段。比如我司的很多表都冗余了 user_name 这个字段。 单表行数超过 500 万行或者单表容量超过 2 GB ，才推荐进行分库分表。 业务上具有唯一特性的字段，即使是组合字段，也必须建成唯一索引。即使在应用层做了非常完善的校验和控制，只要没有唯一索引，根据墨菲定律，必然有脏数据产生。 页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。索引文件具有 B-Tree 的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。关于 MySQL 的知识，诸位可参考 《高性能MySQL》 。 利用延迟关联或者子查询优化超多分页场景。 MySQL 并不是跳过 offset 行，而是取 offset + N 行，然后返回放弃前 offset 行，返回 N 行，那当 offset 特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行 SQL 改写。 建组合索引的时候，区分度最高的在最左边。 不要使用 count(列名) 或 count(常量)来替代 count(*) ，count(*)就是 SQL92 定义 的标准统计行数的语法，跟数据库无关，跟 NULL 和 非NULL 无关。 不得使用外键与级联，一切外键概念必须在应用层解决。外键与级联更新适用于单机低并发，不适合分布式、高并发集群；级联更新是强阻塞，存在数据库更新风暴的风险；外键影响数据库的插入速度。 禁止使用存储过程，存储过程难以调试和扩展，更没有移植性。 数据订正时，删除和修改记录时，要先 select ，避免出现误删除，确认无误才能执行更新语句。 工程规约 高并发服务器建议调小 TCP 协议的 time_wait 超时时间。 调大服务器所支持的最大文件句柄数 (File Descriptor，简写为fd) 。 给 JVM 设置 -XX:+HeapDumpOnOutOfMemoryError 参数，让 JVM 碰到 OOM 场景时输出 dump 信息。 安全规约 隶属于用户个人的页面或者功能必须进行权限控制校验。 用户敏感数据禁止直接展示，必须对展示数据脱敏。 用户输入的 SQL 参数严格使用参数绑定或者 METADATA 字段值限定，防止 SQL 注入， 禁止字符串拼接 SQL 访问数据库。 用户请求传入的任何参数必须做有效性验证。 表单、AJAX 提交必须执行 CSRF 安全过滤。 在使用平台资源，譬如短信、邮件、电话、下单、支付，必须实现正确的防重放限制， 如数量限制、疲劳度控制、验证码校验，避免被滥刷、资损。 关于安全这块可以阅读 《白帽子讲Web安全》 。 阿里巴巴 Java 开发手册]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[迟来的2016年度总结]]></title>
      <url>%2F2017%2F02%2F%E8%BF%9F%E6%9D%A5%E7%9A%842016%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93%2Findex.html</url>
      <content type="text"><![CDATA[青春啊总是在这样分裂的失落的煎熬的夜晚让人伤心我多么想你只能轻轻唱歌 在这正月十二的夜晚，笔者挑灯夜战之后，写下这份迟来的 2016 年度总结。 16 年已经成为过去，这一年，经历了太多事，四月初出学校实习，长辈的离世，各项事务繁杂不清。 2016 ，注定是悲伤的一年。 开学早早来到学校，三月面了阿里的实习内推，当然，历史总是惊人的相似，挂了，不过，作为一个渣学历的本科生，被刷是很正常的，当然，这不是失败的借口。笔者的第二次面试就是笔者现在的公司，然后就实习呗，当然，这次的面试官之前也是阿里的，这面试和笔者阿里实习内推面问的知识点是差不多的，因为岗位都是 Java 服务器端工程师，还告诉笔者阿里现在校招集团要求学校评级是 A 以上，没过也很正常。然后笔者就开始了实习生涯，因为这边给的 Offer 虽然比不上知乎上的随手几十 w 的年薪，但相对来说，也不会算低，并且在成都，笔者17年要面临毕业，学校还有一些事务需要处理，所以暂时不方便离开成都，这也是笔者后面没有再去参加其他面试的原因之一。以上是笔者的实习求职过程，生活的艰辛在这种时候体现得淋漓尽致。 长辈的离世，让我恍如从梦中惊醒，一切都成了昨天，化为了回忆，不知不觉一晃二十余年，一直以为时间还有很多，想起送我的心形夜光石，不知散落到了何处，有的事只能长眠于记忆。 同事准备在成都买房，苦于迟迟没有下手，十月出了新政，错过等一年，希望他能在下一波上涨前买下。 吃饭，唱K，室友 Moses 追女生技术欠佳，屡次失手，室友 RH 就不一样了，成功率蛮高，当然，室友 HB 更是高人，只是不愿出招，还有三四个月就毕业了，四年转瞬即逝，即将各奔东西，不知还能相聚几次。 二十多岁的年纪，迷茫，熬。 晚安吧。 Your browser does not support the audio tag.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[那些你未曾注意的DNS细节]]></title>
      <url>%2F2017%2F01%2F%E9%82%A3%E4%BA%9B%E4%BD%A0%E6%9C%AA%E6%9B%BE%E6%B3%A8%E6%84%8F%E7%9A%84DNS%E7%BB%86%E8%8A%82%2Findex.html</url>
      <content type="text"><![CDATA[DNS 消息是使用二进制数据编写的，查询报文和回答报文有着相同的格式，比如这位朋友写的 asyncdns 就表达得非常清楚。 域名是大小写不敏感的。域名中的每一个标识至多 63 字符长。 一个区域的管理者必须为该区域提供一个主名字服务器和至少一个辅名字服务器。主、辅名字服务器必须是独立和冗余的，以便当某个名字服务器发生故障时不会影响该区域的名字服务。 大家平时经常见到的 A 记录其实是 Address 的缩写，MX 记录是 Mail eXchange 的缩写。RR 就是 Resource Record 的缩写。LDNS 是 Local DNS 的缩写。 根域（Top-Level Domain, TLD） DNS 服务器在运营上使用多台服务器来对应一个 IP 地址，因此尽管 IP 地址只有 13 个，但其实服务器的数量是很多的。参见 Root Servers。 从理论上讲，任何 DNS 查询既可以是迭代的也能是递归的。 DNS 均支持 UDP 和 TCP 访问，但主要使用 UDP。 DNS 原理入门Domain Name SystemRFC 1035]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL Sorting Rows]]></title>
      <url>%2F2016%2F12%2FMySQL-Sorting-Rows%2Findex.html</url>
      <content type="text"><![CDATA[之前一直以为 MySQL 的「ORDER BY」关键字在多列排序时未显式声明排序方式的列会沿用最后显式声明排序方式的列，今天才发现自己弄错了，罪过罪过。在多列排序时，不同的列拥有不同的排序方式，如果未显式声明，则采用默认的升序排序方式。 You can sort on multiple columns, and you can sort different columns in different directions. For example, to sort by type of animal in ascending order, then by birth date within animal type in descending order (youngest animals first), use the following query:123456789101112131415mysql&gt; SELECT name, species, birth FROM pet -&gt; ORDER BY species, birth DESC;+----------+---------+------------+| name | species | birth |+----------+---------+------------+| Chirpy | bird | 1998-09-11 || Whistler | bird | 1997-12-09 || Claws | cat | 1994-03-17 || Fluffy | cat | 1993-02-04 || Fang | dog | 1990-08-27 || Bowser | dog | 1989-08-31 || Buffy | dog | 1989-05-13 || Puffball | hamster | 1999-03-30 || Slim | snake | 1996-04-29 |+----------+---------+------------+ The DESC keyword applies only to the column name immediately preceding it (birth); it does not affect the species column sort order. MySQL 5.7 Reference Manual 4.3.4.4 Sorting Rows]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SQL JOINS]]></title>
      <url>%2F2016%2F09%2FSQL-JOINS%2Findex.html</url>
      <content type="text"><![CDATA[]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[读写分离]]></title>
      <url>%2F2016%2F08%2F%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2Findex.html</url>
      <content type="text"><![CDATA[之前介绍了多数据源的接入，参见 Multiple Datasource ，后来一个数据分析的项目（大部分都是读操作）需要用到读写分离，在分析时读取从库的数据，避免增加对线上数据库的压力，少部分写操作依然写主库，然后再被同步至从库，根据同事的建议，希望采用注解方式实现，从而在开发时只需加上特定的注解即可表明此 DAO 操作主库还是从库，原理依然与之前类似，以下是调整的部分： 为了保护隐私，以下代码部分命名被修改 定义主从数据库的枚举，因为项目中大多数走从库，所以吧 SLAVE 写在了第一个 1234567/** * Created by Poison on 8/15/2016. */public enum Database &#123; SLAVE, MASTER&#125; 定义切换数据源的注解，注解基础可参见 Lesson: Annotations ，根据同事需要只定义了类级别的注解，保留到运行时，读者完全可以根据自身需要自由发挥 1234567891011/** * Created by Poison on 8/16/2016. * This is a marker annotation. * Use this annotation on DAO interface level, represent that all methods in this interface will operate your specified database. */@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)public @interface DataSource &#123; Database value() default Database.SLAVE;&#125; 修改 AOP 相关代码，只有在 DAO 接口上应用了 @DataSource 注解，并且注解值为 Database.MASTER 时才走主库 1234567891011121314151617181920212223242526272829303132/** * Created by Poison on 8/15/2016. */@Aspect@Componentpublic class AroundDataSource &#123; @Around("execution(* me.tianshuang.dao..*.*(..))") public Object doBasicProfiling(ProceedingJoinPoint pjp) throws Throwable &#123; Object result; if (hasMasterAnnotation(pjp)) &#123; DataSourceContextHolder.setDataSource(Database.MASTER); result = pjp.proceed(); DataSourceContextHolder.restoreToSlaveDataSource(); &#125; else &#123; result = pjp.proceed(); &#125; return result; &#125; private boolean hasMasterAnnotation(ProceedingJoinPoint pjp) &#123; Class&lt;?&gt; declaringClass = ((MethodSignature) pjp.getSignature()).getMethod().getDeclaringClass(); if (declaringClass.isAnnotationPresent(DataSource.class)) &#123; DataSource dataSource = declaringClass.getAnnotation(DataSource.class); if (dataSource.value() == Database.MASTER) &#123; return true; &#125; &#125; return false; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Multiple Datasource]]></title>
      <url>%2F2016%2F08%2FMultiple%20Datasource%2Findex.html</url>
      <content type="text"><![CDATA[最近项目中需要接入多个数据源，起初准备让 Mybatis 来进行数据源的动态选择，但查询 Mybatis 的相关文档后，未发现官方对多数据源的支持，并且笔者的项目中 Mybatis 的使用采用全注解的方式，如果实例化两个 SqlSessionFactory ，在全注解使用 Mybatis 的情况下，无法显式指定某个 Mapper 使用哪一个 sqlSessionFactory 。 继续查询相关资料，发现 Spring 自 2.0.1 开始就提供了对动态数据源的支持，参见 Dynamic DataSource Routing ，咳咳，由于文章历史悠久，追溯至2007年，所以在笔者的项目中笔者对其进行了改进，思路依然与原文基本一致，只不过把文中基于XML的相关配置改为了我们项目中的基于 Java Code 的配置。 为了保护隐私，以下代码部分命名被修改 定义多个数据源的枚举，本例中仅包含两个数据源 1234567/** * Created by Poison on 8/15/2016. */enum DataSource &#123; FIRST, SECOND&#125; 定义 DataSourceContextHolder 1234567891011121314151617181920/** * Created by Poison on 8/15/2016. */class DataSourceContextHolder &#123; private static ThreadLocal&lt;DataSource&gt; contextHolder = new ThreadLocal&lt;&gt;(); static void setDataSource(DataSource dataSource) &#123; contextHolder.set(dataSource); &#125; static DataSource getDataSource() &#123; return contextHolder.get(); &#125; static void restoreToFirstDataSource() &#123; contextHolder.set(DataSource.FIRST); &#125;&#125; 定义 RoutingDataSource 1234567891011/** * Created by Poison on 8/15/2016. */class RoutingDataSource extends AbstractRoutingDataSource &#123; @Override protected Object determineCurrentLookupKey() &#123; return DataSourceContextHolder.getDataSource(); &#125;&#125; Datasource 相关配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172@Beanpublic javax.sql.DataSource dataSourceForFirst() &#123; HikariConfig hikariConfig = new HikariConfig(); hikariConfig.setDataSourceClassName(getProperty("jdbc.dataSourceClassName")); hikariConfig.setUsername(getProperty("jdbc.username")); hikariConfig.setPassword(getProperty("jdbc.password")); hikariConfig.setMinimumIdle(Integer.parseInt(getProperty("jdbc.minimumIdle"))); hikariConfig.setMaximumPoolSize(Integer.parseInt(getProperty("jdbc.maximumPoolSize"))); hikariConfig.addDataSourceProperty("serverName", getProperty("jdbc.serverName")); hikariConfig.addDataSourceProperty("port", getProperty("jdbc.port")); hikariConfig.addDataSourceProperty("databaseName", getProperty("jdbc.databaseName")); optimizeHikariConfigForMysql(hikariConfig); return new HikariDataSource(hikariConfig);&#125;private void optimizeHikariConfigForMysql(HikariConfig hikariConfig) &#123; hikariConfig.addDataSourceProperty("cachePrepStmts", true); hikariConfig.addDataSourceProperty("prepStmtCacheSize", 250); hikariConfig.addDataSourceProperty("prepStmtCacheSqlLimit", 2048);&#125;@Beanpublic javax.sql.DataSource dataSourceForSecond() &#123; HikariConfig hikariConfig = new HikariConfig(); hikariConfig.setDataSourceClassName(env.getProperty("jdbc.second.dataSourceClassName")); hikariConfig.setUsername(getProperty("jdbc.second.username")); hikariConfig.setPassword(getProperty("jdbc.second.password")); hikariConfig.setMinimumIdle(Integer.parseInt(env.getProperty("jdbc.second.minimumIdle"))); hikariConfig.setMaximumPoolSize(Integer.parseInt(env.getProperty("jdbc.second.maximumPoolSize"))); hikariConfig.addDataSourceProperty("serverName", getProperty("jdbc.second.serverName")); hikariConfig.addDataSourceProperty("port", getProperty("jdbc.second.port")); hikariConfig.addDataSourceProperty("databaseName", getProperty("jdbc.second.databaseName")); optimizeHikariConfigForMysql(hikariConfig); return new HikariDataSource(hikariConfig);&#125;@Beanpublic javax.sql.DataSource dataSource() &#123; RoutingDataSource routingDataSource = new RoutingDataSource(); Map&lt;Object, Object&gt; targetDataSources = new HashMap&lt;&gt;(); targetDataSources.put(DataSource.FIRST, dataSourceForFirst()); targetDataSources.put(DataSource.SECOND, dataSourceForSecond()); routingDataSource.setTargetDataSources(targetDataSources); routingDataSource.setDefaultTargetDataSource(dataSourceForFirst()); return routingDataSource;&#125;@Beanpublic SqlSessionFactory sqlSessionFactory() throws Exception &#123; SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean(); sessionFactory.setDataSource(dataSource()); sessionFactory.setTypeAliasesPackage("me.tianshuang.domain"); sessionFactory.setTypeHandlers(new TypeHandler[]&#123;new LocalDateTimeTypeHandler()&#125;); org.apache.ibatis.session.Configuration configuration = new org.apache.ibatis.session.Configuration(); configuration.setMapUnderscoreToCamelCase(true); sessionFactory.setConfiguration(configuration); return sessionFactory.getObject();&#125; AOP 相关配置 12345678910111213141516/** * Created by Poison on 8/15/2016. */@Aspect@Componentpublic class AroundDataSource &#123; @Around("execution(* me.tianshuang.dao.second..*.*(..))") public Object doBasicProfiling(ProceedingJoinPoint pjp) throws Throwable &#123; DataSourceContextHolder.setDataSource(DataSource.SECOND); Object result = pjp.proceed(); DataSourceContextHolder.restoreToFirstDataSource(); return result; &#125;&#125; 在对数据源进行路由的控制这方面，采用了 AOP 的思想，在我们的项目中，因为第二个数据源用的频率很低，所以为需要操作第二个数据源的 Mapper 单独建立了一个包 (me.tianshuang.dao.second) ，在此包下的所有 Mapper 的方法在执行前将切换数据源为 SECOND ，执行完方法后又切回数据源 First 。 以上只是切换数据源的一种方案，本文的关键就在于 RoutingDataSource ，而在哪里切换数据源，读者完全可根据自身项目需要选择最适合的方案，该例只是适合笔者所在项目的一个例子。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Git notes]]></title>
      <url>%2F2016%2F07%2FGit-notes%2Findex.html</url>
      <content type="text"><![CDATA[12git submodule initgit submodule update Permanently authenticating with Git repositories can use the .netrc file 123git initgit commit -m "first commit"git remote add origin &lt;url&gt; Push a new local branch to a remote Git repository and track it too:1git push -u origin &lt;branch&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hello, 2016!]]></title>
      <url>%2F2016%2F02%2FHello-2016%2Findex.html</url>
      <content type="text"><![CDATA[风险越高，收益越大 新年，已经没了小时候的些许期待，年复一年。 回顾 2015 ，专业技能方面稳步增长，但感觉驱动自己向前的力量没以前那么强了，可能已经渐渐厌倦大学生活，破茧待出，心里渴望急需闯进外面的世界。春节前考过了科目三，2016 终于不会再在练车上消耗时间。白条和花呗不是好东西。 新的一年，首要的事就是对自己的技术栈查缺补漏，夯实基础，毕竟也就这个学期了，接下来就要面临校招了。玩手机时少花时间在 Twitter 和 Weibo 上，刷多了你会发现这国家真是没救了，但又改变不了什么。把时间迁移到阅读上，利用玩手机的时间多看看出版物书籍，这几年看过的纸质书都堆了好几摞了，不过大部分是技术书，但现在却在慢慢看一些人文方面的书籍，不能把自己完全困在技术圈子里，毕竟技术不是生活的全部。今年下半年应该会搬回自己的宿舍，大一住了一年宿舍，由于偶然的机会结识了核自院的老师，大二大三住在教学楼里，虽然和另外一位朋友一起，但依旧非常安静，特别是晚自习结束后，整座楼寂静无声，有空调有网并且从不断电，正是这个环境给了我自由学习探索的空间，没人打扰，可以自己决定工作到夜间什么时刻，在这里学习的效率也是非常高的，完成了自己知识体系从点到面的一些积累，在这个过程中就好像一扇扇门依次打开。 新年快乐，每个人都有自己的故事。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于此博客]]></title>
      <url>%2F2016%2F01%2F%E5%85%B3%E4%BA%8E%E6%AD%A4%E5%8D%9A%E5%AE%A2%2Findex.html</url>
      <content type="text"><![CDATA[折腾两三天，总算把这个博客搭建起来了。之前大二在 CSDN 写过一段时间的博客，大多数都是关于技术细节的，竟然有 138 篇？一直都有自己搭建博客的想法，想过自己动手码个博客，但无奈自己主要做 Java 的相关开发，前端不是很熟悉，无法做到心里想象中的前端效果，遂放弃自己动手码的想法。看到许多人用 Hexo ，于是 Google 了下相关资料，静态，再看看主题，也不错，遂决定就是 Hexo 了。接下来说说此博客搭建的相关技术吧。 Hexo A fast, simple &amp; powerful blog framework. DigitalOcean 一是免备案，二是 GitHub 的学生认证送了 50 刀的 DigitalOcean 促销码。 Namecheap GitHub 的学生认证赠送了一年的 .me 域名，果断就把 tianshuang.me 拿下。由于众所周知的原因，将 DNS 解析改为 DNSPod 。 Nginx 反向代理，并且之前项目中也用过，就顺手用上了，对于这个博客，反向代理仅用于 admin 插件进行后台编辑文章这部分。 GOGETSSL 防止 HTTP 劫持吧。 嗯，暂时想到的就这些，以后想到再写吧。 2017-02-20 更新日志时隔一年，根据后台的访客数据，我发现访客中的大多数都会来看一看这一篇。今日状态不佳，望着外面氤氲的天空，上午写了一点点代码，想起这篇博客，于是来更新一下。 上面的部分是16年博客建立之初的环境，由于主机在境外，由于众所周知的原因，慢是一种常态，更严重的是有时根本无法连通，开始我只是把部分图片资源转移到了七牛上，再后面直接把这个域名直接加速，后来学生主机到期，就把静态博客移到了 Github Pages 上，但是怎么弄主机都在境外，只要一旦没击中缓存，就要从境外主机回源，速度不可直视。趁这几天有空，将 blog 挪一下窝，一切为了速度，首先将 DNS 解析更换为 CloudXNS ，然后将 blog 文件放至阿里云 OSS ，写了个增量更新的脚本，还是一样的一键发布，再搭配阿里云的 CDN ，之所以选阿里云是因为之前用七牛的 CDN 时，七牛那边暂不支持 HTTP 到 HTTPS 的 301/302 重定向，七牛的技术给的答复也只是支持的时候会通知，腾讯云的 CDN 也暂时不支持，而阿里云这边是支持的，之所以一定要 HTTPS ，是因为实在受不了右下角经常被插入小广告。暂时就做以上的调整，先试试效果。 2017-02-25 更新日志将博客增量上传到 OSS 的 Python 脚本上传到了 Github 上，需要的朋友自取， aliyun-oss-sync ，因为使用阿里云 CDN 加速 OSS 之后， OSS 中的文件变化后 CDN 会自动清空相应文件的 CDN 缓存，所以每次只要 UPDATE 到 OSS 即完成发布。 2017-03-03 更新日志因为用户直接在浏览器输入 tianshuang.me 的话，浏览器默认使用 HTTP 协议访问， server 端返回 301/302 让客户端重定向到 https://tianshuang.me/ ，而在这一次请求及响应依然是明文传输的，所以仍然存在被中间人攻击的可能。为了尽可能降低这种可能性，我们希望配置 Strict-Transport-Security 这个 header ，这里有一篇文章讲得比较清楚，参见 HSTS详解 ，而本站使用了阿里云的 CDN ， CDN 的控制面板里可以手动配置 HTTP header ，但阿里云仅开放了部分 header 供用户手动配置，故已经提交了工单，希望开放此 Strict-Transport-Security header 供用户手动配置。]]></content>
    </entry>

    
  
  
</search>
